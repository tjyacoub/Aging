{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ON_OF = pd.read_csv(\"ON_OF.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_YN_ON = pd.read_csv(\"YN_ON.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_YF_OF = pd.read_csv(\"YF_OF.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_YN_YF = pd.read_csv(\"YN_YF.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ON = df_ON_OF[[19,4,6,7,8,9]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_OF = df_ON_OF[[19,4,10,11,12,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_YN = df_YN_ON[[19,4,6,7,8,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_YF = df_YN_YF[[19,4,10,11,12,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_dup(d):\n",
    "    d = d.drop_duplicates(subset='gene', keep='first')\n",
    "    return d\n",
    "\n",
    "def merge(d1, d2):\n",
    "    return pd.merge(d1, d2, how='outer', on=['gene','width'])\n",
    "\n",
    "def merge2(d1, d2):\n",
    "    return pd.merge(d1, d2, how='outer', on='gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dft = merge(df_ON, df_OF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dft = merge(dft, df_YN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dft = merge(dft, df_YF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dft = drop_dup(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dft.dropna(thresh=(2), axis=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dft = dft[pd.notnull(dft).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict = {'AT2.young.flu.20150416': 'YF', 'AT2.old.naive.20150416': 'ON', \n",
    "                 'AT2.old.flu.20150416': 'OF', 'AT2.young.naive.20150416': 'YN'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rename_cols(df, state_dict):\n",
    "    cols = df.columns\n",
    "    temp_cols = list(cols)\n",
    "    #print temp_cols\n",
    "    for c in range(len(cols)):\n",
    "        state_name = cols[c][:-2]\n",
    "        #sample_num = cols[c][-2:]\n",
    "        total_name = cols[c]\n",
    "        #print state_name\n",
    "        if state_name in state_dict:\n",
    "            new_state_name = state_dict[state_name]\n",
    "            new_col = total_name.replace(state_name, new_state_name)\n",
    "            temp_cols[c] = new_col\n",
    "            #print abb_pair_dict[state_name]\n",
    "    df.columns = temp_cols\n",
    "    #print temp_cols\n",
    "    return df\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = rename_cols(df, state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14285"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def df_to_names(df):\n",
    "    \n",
    "    name_dict = {}\n",
    "        \n",
    "    for i in range(2,len(df.columns)):\n",
    "        name = df.columns[i][:-2]\n",
    "        if name in name_dict:\n",
    "            name_dict[name].append(i)\n",
    "        else:\n",
    "            name_dict[name] = [i]\n",
    "            \n",
    "    return name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_dict = df_to_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unique(a, b):\n",
    "    return list([a[i] for i in range(1,len(a)) if a[i] not in b])\n",
    "def intersect(a, b):\n",
    "    return list(set(a) & set(b))\n",
    "def union(a, b):\n",
    "    return list(set(a) | set(b))\n",
    "def intersect3(a, b, c):\n",
    "    return list(set(a) & set(b) & set(c))\n",
    "\n",
    "def unique3(a, b, c, index):\n",
    "    uniques = [0 for i in range(3)]\n",
    "    uniques[0] = list([a[i] for i in range(1,len(a)) if a[i] not in b and a[i] not in c])\n",
    "    uniques[1] = list([b[i] for i in range(1,len(b)) if b[i] not in a and b[i] not in c])\n",
    "    uniques[2] = list([c[i] for i in range(1,len(c)) if c[i] not in a and c[i] not in b])\n",
    "    return uniques[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t_stat(df, names):\n",
    "    \n",
    "    ### Df has samples only, no gene\n",
    "    #print df\n",
    "    #names = df_to_names(df)\n",
    "    #print \"t-stat names\", names #names[0], name_dict[names[0]]\n",
    "    n_samples1 = len(name_dict[names[0]])\n",
    "    n_samples2 = len(name_dict[names[1]])\n",
    "    \n",
    "    index1 = 1\n",
    "    index2 = index1 + n_samples1\n",
    "    \n",
    "    width = df['width']\n",
    "    #print \"nsamps\", n_samples1, n_samples2\n",
    "    indices1 = [index1 + i for i in range(n_samples1)]\n",
    "    indices2 = [index2 + i for i in range(n_samples2)]\n",
    "    \n",
    "    values1 = [df[df.columns[i]] for i in indices1]\n",
    "    values2 = [df[df.columns[i]] for i in indices2]\n",
    "    \n",
    "    mean1 = sum(values1)/n_samples1\n",
    "    mean2 = sum(values2)/n_samples2\n",
    "    \n",
    "    var1_num = [(values1[i] - mean1)**2 for i in range(n_samples1)]\n",
    "    var2_num = [(values2[i] - mean2)**2 for i in range(n_samples2)]\n",
    "    \n",
    "    var1 = sum(var1_num)/(n_samples1 - 1)\n",
    "    var2 = sum(var2_num)/(n_samples2 - 1)\n",
    "    \n",
    "    t_stat = (mean1 - mean2) / (var1/n_samples1 + var2/n_samples2)**0.5\n",
    "    pval = stats.t.sf(np.abs(t_stat), n_samples1-1)*2 \n",
    "    \n",
    "    logfc = np.log2(mean2/mean1)\n",
    "    \n",
    "    diff = (mean2 - mean1) * width\n",
    "    diff2 = (mean2 - mean1)\n",
    "    \n",
    "    return [pval, logfc, diff, mean1, diff2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Create new temp dataframe with cols ['samp1a','samp1b','samp2a','samp2b','gene']\n",
    "### Add cols for logfc, pval\n",
    "def names_to_df(names):\n",
    "       \n",
    "    # For first name    \n",
    "    #print \"names to df\", names\n",
    "    indices = list(name_dict[names[0]])\n",
    "    l = len(indices)\n",
    "    indices.insert(0,1)\n",
    "    indices.insert(0,0)\n",
    "    #print indices\n",
    "    df_temp1 = df.ix[:,indices]\n",
    "    #print df_temp1\n",
    "    \n",
    "    # For second name\n",
    "    indices = list(name_dict[names[1]])\n",
    "    l = len(indices)\n",
    "    indices.insert(0,1)\n",
    "    indices.insert(0,0)\n",
    "    df_temp2 = df.ix[:,indices]\n",
    "    \n",
    "    dft = pd.merge(df_temp1, df_temp2, how='outer', on=['gene','width']);\n",
    "    \n",
    "    dft = dft.ix[1:];\n",
    "    dft_float = dft.ix[:,1:].astype('float');\n",
    "    dft_float = dft_float[dft_float > 0];\n",
    "\n",
    "    #print dft_float\n",
    "    dft['pval'], dft['logfc'], dft['diff'], dft['mean'], dft['diff_only'] = t_stat(dft_float, names)\n",
    "\n",
    "    return dft\n",
    "    #dft = merge(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs_rel = [['YN','ON'],['YN','YF'],['ON','OF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d28a54734861>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pairs' is not defined"
     ]
    }
   ],
   "source": [
    "tdf = names_to_df(pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-189883e11670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pval'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tdf' is not defined"
     ]
    }
   ],
   "source": [
    "tdf = tdf[tdf['pval'] < 0.05];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tdfup = tdf[tdf['diff'] > 0]\n",
    "tdfdn = tdf[tdf['diff'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nup = np.sum(tdfup['diff'])\n",
    "ndn = np.sum(tdfdn['diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reset_pairs(df):\n",
    "    \n",
    "    name_dict = df_to_names(df)\n",
    "    names = name_dict.keys()\n",
    "    n_names = len(names)\n",
    "    pairs = [[[names[i], names[j]] for i in range(n_names) if i != j] for j in range(n_names)]\n",
    "    pairs = [pair for sublist in pairs for pair in sublist]\n",
    "    return pairs\n",
    "\n",
    "pairs = reset_pairs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_df(df, pcut = 0.05, fcut = 0.15, dcut = 25, mcut = 5):\n",
    "    \n",
    "    ### Filter all by pvalue\n",
    "    df = df[df['pval'] < pcut]\n",
    "    \n",
    "    ## Highly upregulated\n",
    "    df1 = df[df['diff'] > dcut]\n",
    "    \n",
    "    ## Highly downregulated\n",
    "    df2 = df[df['diff'] < -dcut]\n",
    "    \n",
    "    ## Weakly upregulated\n",
    "    df3 = df[df['diff'] < dcut]\n",
    "    df3 = df3[df3['diff'] > 0]\n",
    "    \n",
    "    ## Weakly downregulated\n",
    "    df4 = df[df['diff'] > -fcut]\n",
    "    df4 = df4[df4['diff'] < 0]\n",
    "    \n",
    "    return [df1, df2, df3, df4]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_grps(df, pcut = 0.05, fcut = 0, dcut = 0, mcut = 0):\n",
    "    \n",
    "    ### Filter all by pvalue\n",
    "    df = df[df['pval'] < pcut]\n",
    "    \n",
    "    ## Highly upregulated\n",
    "    df1 = df[df['diff'] > dcut]\n",
    "    df1 = df1[df1['mean'] > mcut]\n",
    "    df1 = df1[df1['logfc'] > fcut]\n",
    "    \n",
    "    ## Highly downregulated\n",
    "    df2 = df[df['diff'] < dcut]\n",
    "    df2 = df2[df2['mean'] > mcut]\n",
    "    df2 = df2[df2['logfc'] < -fcut]\n",
    "\n",
    "    return [df1, df2]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grp_stats(group):\n",
    "    \n",
    "    mean_diff = round(np.mean(group['diff']),0)\n",
    "    diff_low = round(np.mean(group['diff_only']),2)\n",
    "    mean_val = round(np.mean(group['mean']),2)\n",
    "    tot = mean_diff*len(group)\n",
    "    return [len(group), diff_low, tot/1000000, mean_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n_groups = 2\n",
    "#for p1 in range(1,2):#len(pairs_rel)):\n",
    "\n",
    "out1 = open('YN_YF_unique_up','w')\n",
    "\n",
    "def common_stats(pairs):\n",
    "    \n",
    "    pair1 = pairs[0]\n",
    "    print pair1\n",
    "    df1 = names_to_df(pair1)\n",
    "    df1_groups = filter_grps(df1)\n",
    "    df1_genes = [group['gene'] for group in df1_groups]\n",
    "    \n",
    "    pair2 = pairs[1]\n",
    "    print pair2\n",
    "    df2 = names_to_df(pair2)\n",
    "    df2_groups = filter_grps(df2)\n",
    "    df2_genes = [group['gene'] for group in df2_groups]\n",
    "        \n",
    "    common_genes = [pd.DataFrame(intersect(df1_genes[i], df2_genes[i])) for i in range(n_groups)]\n",
    "    #return df1_genes[0], df2_genes[0]\n",
    "    #break\n",
    "    unique_genes1 = [pd.DataFrame(unique(list(df1_genes[i]), list(df2_genes[i]))) for i in range(n_groups)]\n",
    "    unique_genes2 = [pd.DataFrame(unique(list(df2_genes[i]), list(df1_genes[i]))) for i in range(n_groups)]\n",
    "    \n",
    "    for i in range(n_groups):\n",
    "        common_genes[i].columns = ['gene']\n",
    "        unique_genes1[i].columns = ['gene']\n",
    "        unique_genes2[i].columns = ['gene']\n",
    "    \n",
    "    upgenes1 = unique(list(df1_genes[0]), list(df2_genes[0]))\n",
    "    upgenes2 = unique(list(df2_genes[0]), list(df1_genes[0]))\n",
    "    print \"# in common\", [len(common_genes[i]) for i in range(n_groups)]\n",
    "    print \"# unique in 1\", [len(unique_genes1[i]) for i in range(n_groups)]\n",
    "    print \"# in group1\", [len(genes) for genes in df1_genes]\n",
    "        #print common_genes[0]\n",
    "        ## Of the common genes, which are in first pair\n",
    "        #print df1_groups[0]\n",
    "    df1_common = [pd.merge(common_genes[i], df1_groups[i], how='left') for i in range(n_groups)]\n",
    "    df2_common = [pd.merge(common_genes[i], df2_groups[i], how='left') for i in range(n_groups)]\n",
    "    \n",
    "    #@df1[~ (df1_groups[0].gene.isin(df1_common.id1) & df1.id2.isin(df2.id2))]\n",
    "    \n",
    "    df1_unique = [pd.merge(unique_genes1[i], df1_groups[i], how='left') for i in range(n_groups)]\n",
    "    df2_unique = [pd.merge(unique_genes2[i], df2_groups[i], how='left') for i in range(n_groups)]\n",
    "    \n",
    "    dfs_uniq = [df1_unique, df2_unique]\n",
    "    dfs_comm = [df1_common, df2_common]\n",
    "    dfs_tots = [df1_groups, df2_groups]\n",
    "    #dfup_comm = df1_common[0]\n",
    "    #ne = (df1 != df2).any(1)\n",
    "        #print \"In common with pair 1\"\n",
    "        \n",
    "        ## In\n",
    "    d_graph = []\n",
    "    for i in range(len(df1_groups)):\n",
    "        \n",
    "        if i==0: print \"UPREG\"\n",
    "        else: print \"DOWN REG\"\n",
    "        \n",
    "        print \"FIRST GROUP\"\n",
    "        print \"Total\"\n",
    "        \n",
    "        print grp_stats(df1_groups[i])\n",
    "\n",
    "        print \"Common\"\n",
    "        print grp_stats(df1_common[i])\n",
    "        \n",
    "        comm_1 = grp_stats(df1_common[i])[2]\n",
    "        \n",
    "        print \"Unique\"\n",
    "        print grp_stats(df1_unique[i])\n",
    "        \n",
    "        uniq_1 = grp_stats(df1_unique[i])[2]\n",
    "\n",
    "        d1 = [comm_1, uniq_1]\n",
    "        d_graph.append(d1)\n",
    "        \n",
    "        print \"Second Group\"\n",
    "        print \"Total\"\n",
    "        print grp_stats(df2_groups[i])\n",
    "        \n",
    "        print \"Common\"\n",
    "        comm_2 = grp_stats(df2_common[i])[2]\n",
    "        print grp_stats(df2_common[i])\n",
    "        \n",
    "        print \"Unique\"\n",
    "        uniq_2 = grp_stats(df2_unique[i])[2]\n",
    "        print grp_stats(df2_unique[i])\n",
    "        \n",
    "        d2 = [comm_2, uniq_2]\n",
    "        d_graph.append(d2)\n",
    "        print '\\n'\n",
    "    \n",
    "    return d_graph #dfs_uniq, dfs_comm, dfs_tots\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n_groups = 2\n",
    "#for p1 in range(1,2):#len(pairs_rel)):\n",
    "\n",
    "out1 = open('YN_YF_unique_up','w')\n",
    "\n",
    "def common_stats_graph(pairs):\n",
    "    \n",
    "    pair1 = pairs[0]\n",
    "    print pair1\n",
    "    df1 = names_to_df(pair1)\n",
    "    df1_groups = filter_grps(df1, fcut=0.1)\n",
    "    df1_genes = [group['gene'] for group in df1_groups]\n",
    "    \n",
    "    pair2 = pairs[1]\n",
    "    print pair2\n",
    "    df2 = names_to_df(pair2)\n",
    "    df2_groups = filter_grps(df2, fcut=0.1)\n",
    "    df2_genes = [group['gene'] for group in df2_groups]\n",
    "    \n",
    "    common_genes = [pd.DataFrame(intersect(df1_genes[i], df2_genes[i])) for i in range(n_groups)]\n",
    "    #return df1_genes[0], df2_genes[0]\n",
    "    #break\n",
    "    unique_genes1 = [pd.DataFrame(unique(list(df1_genes[i]), list(df2_genes[i]))) for i in range(n_groups)]\n",
    "    unique_genes2 = [pd.DataFrame(unique(list(df2_genes[i]), list(df1_genes[i]))) for i in range(n_groups)]\n",
    "    \n",
    "    for i in range(n_groups):\n",
    "        common_genes[i].columns = ['gene']\n",
    "        unique_genes1[i].columns = ['gene']\n",
    "        unique_genes2[i].columns = ['gene']\n",
    "    \n",
    "    upgenes1 = unique(list(df1_genes[0]), list(df2_genes[0]))\n",
    "    upgenes2 = unique(list(df2_genes[0]), list(df1_genes[0]))\n",
    "    print \"# in common\", [len(common_genes[i]) for i in range(n_groups)]\n",
    "    print \"# unique in 1\", [len(unique_genes1[i]) for i in range(n_groups)]\n",
    "    print \"# in group1\", [len(genes) for genes in df1_genes]\n",
    "        #print common_genes[0]\n",
    "        ## Of the common genes, which are in first pair\n",
    "        #print df1_groups[0]\n",
    "    df1_common = [pd.merge(common_genes[i], df1_groups[i], how='left') for i in range(n_groups)]\n",
    "    df2_common = [pd.merge(common_genes[i], df2_groups[i], how='left') for i in range(n_groups)]\n",
    "    \n",
    "    #@df1[~ (df1_groups[0].gene.isin(df1_common.id1) & df1.id2.isin(df2.id2))]\n",
    "    \n",
    "    df1_unique = [pd.merge(unique_genes1[i], df1_groups[i], how='left') for i in range(n_groups)]\n",
    "    df2_unique = [pd.merge(unique_genes2[i], df2_groups[i], how='left') for i in range(n_groups)]\n",
    "    \n",
    "    dfs_uniq = [df1_unique, df2_unique]\n",
    "    dfs_comm = [df1_common, df2_common]\n",
    "    dfs_tots = [df1_groups, df2_groups]\n",
    "    #dfup_comm = df1_common[0]\n",
    "    #ne = (df1 != df2).any(1)\n",
    "        #print \"In common with pair 1\"\n",
    "        \n",
    "        ## In\n",
    "    p1_graph = []\n",
    "    p2_graph = []\n",
    "    p_graph = []\n",
    "    for i in range(len(df1_groups)):\n",
    "            \n",
    "        if i==0: card = 1\n",
    "        else: card = -1\n",
    "                \n",
    "        comm_1 = grp_stats(df1_common[i])[2]\n",
    " \n",
    "        uniq_1 = grp_stats(df1_unique[i])[2]\n",
    "\n",
    "        d1 = [card*comm_1, card*uniq_1]\n",
    "        p_graph.append(d1)\n",
    "        \n",
    "        comm_2 = grp_stats(df2_common[i])[2]\n",
    "  \n",
    "        uniq_2 = grp_stats(df2_unique[i])[2]\n",
    "\n",
    "        \n",
    "        d2 = [card*comm_2, card*uniq_2]\n",
    "        p_graph.append(d2)\n",
    "    \n",
    "    pd.DataFrame(p_graph, columns=['a', 'b']).plot(kind='bar',stacked=True, title = pairs)\n",
    "    #plt.axhline(0, color='k')\n",
    "    #return p_graph #dfs_uniq, dfs_comm, dfs_tots\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YN', 'YF']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'filter_grps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8871f9201c74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md_graph_age0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_stats_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'YN'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'YF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ON'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'OF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-dac470326e81>\u001b[0m in \u001b[0;36mcommon_stats_graph\u001b[0;34m(pairs)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mpair1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdf1_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_grps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdf1_genes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gene'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf1_groups\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'filter_grps' is not defined"
     ]
    }
   ],
   "source": [
    "d_graph_age0 = common_stats_graph([['YN','YF'],['ON','OF']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def uniq_ratio(lst):\n",
    "    return [lst[i][1]/lst[i][0] for i in range(len(lst))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_graph_flu = common_stats_graph([['YN','YF'],['ON','OF']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(d_graph_flu).plot(kind='bar',stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(uniq_ratio(d_graph)).plot(kind='bar',stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfY_up = dfsuniq[0][0].ix[:,[0,10,11]]\n",
    "dfY_dn = dfsuniq[0][1].ix[:,[0,10,11]]\n",
    "dfO_up = dfsuniq[1][0].ix[:,[0,10,11]]\n",
    "dfO_dn = dfsuniq[1][1].ix[:,[0,10,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(np.random.rand(4, 2), columns=['a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfY_up_comm = dfs_comm[0][0].ix[:,[0,10,11]]\n",
    "dfY_dn_comm = dfs_comm[0][1].ix[:,[0,10,11]]\n",
    "dfO_up_comm = dfs_comm[1][0].ix[:,[0,10,11]]\n",
    "dfO_dn_comm = dfs_comm[1][1].ix[:,[0,10,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfY_up_comm.to_csv('dfY_up_comm.txt',sep='\\t', index=False)\n",
    "dfY_dn_comm.to_csv('dfY_dn_comm.txt',sep='\\t', index=False)\n",
    "dfO_up_comm.to_csv('dfO_up_comm.txt',sep='\\t', index=False)\n",
    "dfO_dn_comm.to_csv('dfO_dn_comm.txt',sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfY_up.to_csv('dfY_up.txt',sep='\\t', index=False)\n",
    "dfY_dn.to_csv('dfY_dn.txt',sep='\\t', index=False)\n",
    "dfO_up.to_csv('dfO_up.txt',sep='\\t', index=False)\n",
    "dfO_dn.to_csv('dfO_dn.txt',sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs_comm, dfs_uniq, dfsgrps = common_stats([['YN','YF'],['ON','OF']])\n",
    "## Commonly regulated genes used in aging and old flu are 50% higher in flu.\n",
    "## CRGs comprise 20% in upreg, but only 5% in ON_OF downerg\n",
    "## Much more downreg URGs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfsuniq[0].sort('diff', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_grps = 2\n",
    "#for p1 in range(1,2):#len(pairs_rel)):\n",
    "\n",
    "def common_stats3():\n",
    "    \n",
    "    pairs = [['YN', 'ON'], ['ON','OF'],['YN','YF']]\n",
    "    n_pairs = len(pairs)\n",
    "    dfs = [names_to_df(pair) for pair in pairs]\n",
    "    dfgrps = [filter_grps(dft) for dft in dfs]\n",
    "    dfgenes = [[group['gene'] for group in grps] for grps in dfgrps]\n",
    "    \n",
    "    ## returns 1 set per group\n",
    "    common_genes = [pd.DataFrame(intersect3(dfgenes[0][i], dfgenes[1][i], dfgenes[2][i])) for i in range(n_groups)]\n",
    "    \n",
    "    ## returns list of 3 sets per group\n",
    "    unique_genes = [[pd.DataFrame(unique3(list(dfgenes[0][i]), list(dfgenes[1][i]), list(dfgenes[2][i]), j)) \\\n",
    "                    for j in range(n_pairs)] for i in range(n_grps)]\n",
    "                    #for i in range(n_groups)]\n",
    "    #print len(unique_genes)\n",
    "    for i in range(n_grps):\n",
    "        common_genes[i].columns = ['gene']\n",
    "        for j in range(n_pairs):\n",
    "            unique_genes[i][j].columns = ['gene']\n",
    "    \n",
    "    dfs_comm = [[pd.merge(common_genes[i], dfgrps[j][i], how='left') for i in range(n_grps)] for j in range(n_pairs)]\n",
    "    dfs_uniq = [[pd.merge(unique_genes[i][j], dfgrps[j][i], how='left') for i in range(n_grps)] for j in range(n_pairs)]\n",
    "\n",
    "    for i in range(n_grps):\n",
    "        \n",
    "        print '\\n'\n",
    "        if i==0: print \"UPREG\"\n",
    "        else: print \"DOWN REG\"\n",
    "        print '\\n'\n",
    "        \n",
    "        for j in range(n_pairs):\n",
    "            \n",
    "            print '\\n'\n",
    "            print \"PAIR\", pairs[j]\n",
    "        \n",
    "            print \"Total\"\n",
    "            print grp_stats(dfgrps[j][i])\n",
    "            print \"Common\"\n",
    "            print grp_stats(dfs_comm[j][i])\n",
    "            print \"Unique\"\n",
    "            print grp_stats(dfs_uniq[j][i])\n",
    "\n",
    "    return dfs_comm, dfs_uniq, dfsgrps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs_comm[0][0][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs_comm, dfs_uniq, dfsgrps = common_stats3()\n",
    "### common genes upgregulated used same amount by Old illness and Young illness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs_comm[2][1].sort('diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upcomm = common_stats([['YN','ON'],['ON','OF']]);\n",
    "### Common are general purpose upreg/downreg??? between aging and flu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Needs dataframe with cols ('gene', 'logfc', 'pval')\n",
    "\n",
    "def filter_genes(df, pcut = 0.05, fcut = 1.4):\n",
    "    \n",
    "    df_pcut = df[df['pval'] < pcut]\n",
    "    \n",
    "    df_fc_up = df_pcut[df_pcut['logfc'] > fcut]\n",
    "    \n",
    "    df_fc_dn = df_pcut[df_pcut['logfc'] < -fcut]\n",
    "    \n",
    "    df_pv_up = df_pcut[df_pcut['logfc'] < fcut]\n",
    "    df_pv_up = df_pv_up[df_pv_up['logfc'] > 0]\n",
    "    \n",
    "    df_pv_dn = df_pcut[df_pcut['logfc'] < 0]\n",
    "    df_pv_dn = df_pv_dn[df_pv_dn['logfc'] > -fcut]\n",
    "\n",
    "    fc_up_genes = df_fc_up['gene']\n",
    "    fc_dn_genes = df_fc_dn['gene']\n",
    "    pv_up_genes = df_pv_up['gene']\n",
    "    pv_dn_genes = df_pv_dn['gene']\n",
    "    \n",
    "    #n_up_fc = sum(df_fc_up.ix[:,'up'])\n",
    "    #n_dn_fc = sum(df_fc_dn.ix[:,'dn'])\n",
    "    #n_up_pv = sum(df_pv_up.ix[:,'up'])\n",
    "    #n_dn_pv = sum(df_pv_dn.ix[:,'dn'])\n",
    "\n",
    "    return [fc_up_genes, fc_dn_genes, pv_up_genes, pv_dn_genes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_counts(names):\n",
    "    \n",
    "    dft = names_to_df(names)\n",
    "    dft_genes = filter_genes(dft)\n",
    "    dft_counts = [len(genes) for genes in dft_genes]\n",
    "    return dft_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_pair_counts(name_pairs):\n",
    "    \n",
    "    dft1 = names_to_df(name_pairs[0])\n",
    "    dft2 = names_to_df(name_pairs[1])\n",
    "    \n",
    "    dft1_genes = filter_genes(dft1)\n",
    "    dft2_genes = filter_genes(dft2)\n",
    "    \n",
    "    common_genes = [intersect(dft1_genes[i], dft2_genes[i]) for i in range(len(dft1_genes))]\n",
    "    common_counts = [len(genes) for genes in common_genes]\n",
    "    return common_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_counts(pairs):\n",
    "    \n",
    "    pairs = reset_pairs(df)\n",
    "    pairs2 = list(pairs)\n",
    "    \n",
    "    for p in range(len(pairs)):\n",
    "        #pair in pairs:\n",
    "        counts = get_counts(pairs2[p])\n",
    "        pairs2[p].append(counts)\n",
    "        \n",
    "    return pairs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def common_counts(pairs):\n",
    "    \n",
    "    pairs = reset_pairs(df)\n",
    "    pairs_temp = list(pairs)\n",
    "    data = []\n",
    "    \n",
    "    for p in range(len(pairs)):\n",
    "        pair1 = pairs[p]\n",
    "        \n",
    "        for p2 in range(p+1,len(pairs)): \n",
    "            pair2 = pairs[p2]\n",
    "            #if pair1 != pair2:\n",
    "            counts = pair_pair_counts([pair1, pair2])\n",
    "            data12 = [[pair1, pair2],[counts]]\n",
    "            data.append(data12)\n",
    "            \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def common_ratio(pairs):\n",
    "    \n",
    "    pairs = reset_pairs(df)\n",
    "    pairs_temp = list(pairs)\n",
    "    data = []\n",
    "    \n",
    "    for p in range(len(pairs)):\n",
    "        pair1 = pairs[p]\n",
    "        \n",
    "        for p2 in range(p+1,len(pairs)): \n",
    "            pair2 = pairs[p2]\n",
    "            #if pair1 != pair2:\n",
    "            counts = pair_pair_counts([pair1, pair2])\n",
    "            data12 = [[pair1, pair2],float(counts[0])/float(counts[1])]\n",
    "            data.append(data12)\n",
    "            \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def uncommon_counts(pairs):\n",
    "    \n",
    "    pairs = reset_pairs(df)\n",
    "    pairs_temp = list(pairs)\n",
    "    data = []\n",
    "    \n",
    "    for p in range(len(pairs)):\n",
    "        pair1 = pairs[p]\n",
    "        counts1 = get_counts(pair1)\n",
    "        for p2 in range(p+1,len(pairs)): \n",
    "            pair2 = pairs[p2]\n",
    "            #if pair1 != pair2:\n",
    "            counts2 = get_counts(pair2)\n",
    "            counts_pair = pair_pair_counts([pair1, pair2])\n",
    "            data12 = [[pair1, counts1, pair2, counts2],[counts_pair]]\n",
    "            data.append(data12)\n",
    "            \n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
