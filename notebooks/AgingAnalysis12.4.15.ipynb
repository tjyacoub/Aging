{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ON_OF = pd.read_csv(\"ON_OF.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_YN_ON = pd.read_csv(\"YN_ON.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_YF_OF = pd.read_csv(\"YF_OF.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_YN_YF = pd.read_csv(\"YN_YF.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ON = df_ON_OF[[19,6,7,8,9]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_OF = df_ON_OF[[19,10,11,12,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_YN = df_YN_ON[[19,6,7,8,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_YF = df_YN_YF[[19,10,11,12,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dft = pd.merge(df_ON, df_OF, how='outer', on='gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dft = pd.merge(dft, df_YN, how='outer', on='gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dft = pd.merge(dft, df_YF, how='outer', on='gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dft.dropna(thresh=(2), axis=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dft = dft[pd.notnull(dft).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_name_dict = {'AT2.young.flu.20150416': 'YF', 'AT2.old.naive.20150416': 'ON', \n",
    "                 'AT2.old.flu.20150416': 'OF', 'AT2.young.naive.20150416': 'YN'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rename_cols(df, state_dict):\n",
    "    cols = df.columns\n",
    "    temp_cols = list(cols)\n",
    "    #print temp_cols\n",
    "    for c in range(len(cols)):\n",
    "        state_name = cols[c][:-2]\n",
    "        #sample_num = cols[c][-2:]\n",
    "        total_name = cols[c]\n",
    "        #print state_name\n",
    "        if state_name in abb_pair_dict:\n",
    "            new_state_name = abb_pair_dict[state_name]\n",
    "            new_col = total_name.replace(state_name, new_state_name)\n",
    "            temp_cols[c] = new_col\n",
    "            #print abb_pair_dict[state_name]\n",
    "    df.columns = temp_cols\n",
    "    #print temp_cols\n",
    "    return df\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'abb_pair_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b13764497884>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrename_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_name_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-0fd2368a03a5>\u001b[0m in \u001b[0;36mrename_cols\u001b[0;34m(df, state_dict)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtotal_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#print state_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mstate_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mabb_pair_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mnew_state_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabb_pair_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mnew_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'abb_pair_dict' is not defined"
     ]
    }
   ],
   "source": [
    "df = rename_cols(dft, state_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reset_pairs(df):\n",
    "    name_dict = df_to_names(df)\n",
    "    names = name_dict.keys()\n",
    "    n_names = len(names)\n",
    "    pairs = [[[names[i], names[j]] for i in range(n_names) if i != j] for j in range(n_names)]\n",
    "    pairs = [pair for sublist in pairs for pair in sublist]\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_dict = df_to_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OF': [5, 6, 7, 8],\n",
       " 'ON': [1, 2, 3, 4],\n",
       " 'YF': [13, 14, 15, 16],\n",
       " 'YN': [9, 10, 11, 12]}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gene', 'AT2.old.naive.20150416.1', 'AT2.old.naive.20150416.2', 'AT2.old.naive.20150416.3', 'AT2.old.naive.20150416.4', 'AT2.old.flu.20150416.1', 'AT2.old.flu.20150416.2', 'AT2.old.flu.20150416.3', 'AT2.old.flu.20150416.4', 'AT2.young.naive.20150416.1', 'AT2.young.naive.20150416.2', 'AT2.young.naive.20150416.3', 'AT2.young.naive.20150416.4', 'AT2.young.flu.20150416.1', 'AT2.young.flu.20150416.2', 'AT2.young.flu.20150416.3', 'AT2.young.flu.20150416.4']\n"
     ]
    }
   ],
   "source": [
    "df = rename_cols(dft, state_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unique(a, b):\n",
    "    return list(set(a) != set(b))\n",
    "def intersect(a, b):\n",
    "    return list(set(a) & set(b))\n",
    "def union(a, b):\n",
    "    return list(set(a) | set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t_stat(df, names):\n",
    "    \n",
    "    ### Df has samples only, no gene\n",
    "    #print df\n",
    "    #names = df_to_names(df)\n",
    "    #print \"t-stat names\", names #names[0], name_dict[names[0]]\n",
    "    n_samples1 = len(name_dict[names[0]])\n",
    "    n_samples2 = len(name_dict[names[1]])\n",
    "    \n",
    "    index1 = 0\n",
    "    index2 = index1 + n_samples1\n",
    "    \n",
    "    #print \"nsamps\", n_samples1, n_samples2\n",
    "    indices1 = [index1 + i for i in range(n_samples1)]\n",
    "    indices2 = [index2 + i for i in range(n_samples2)]\n",
    "    \n",
    "    values1 = [df[df.columns[i]] for i in indices1]\n",
    "    values2 = [df[df.columns[i]] for i in indices2]\n",
    "    \n",
    "    mean1 = sum(values1)/n_samples1\n",
    "    mean2 = sum(values2)/n_samples2\n",
    "    \n",
    "    var1_num = [(values1[i] - mean1)**2 for i in range(n_samples1)]\n",
    "    var2_num = [(values2[i] - mean2)**2 for i in range(n_samples2)]\n",
    "    \n",
    "    var1 = sum(var1_num)/(n_samples1 - 1)\n",
    "    var2 = sum(var2_num)/(n_samples2 - 1)\n",
    "    \n",
    "    t_stat = (mean1 - mean2) / (var1/n_samples1 + var2/n_samples2)**0.5\n",
    "    pval = stats.t.sf(np.abs(t_stat), n_samples1-1)*2 \n",
    "    \n",
    "    logfc = np.log2(mean2/mean1)\n",
    "    \n",
    "    return [pval, logfc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def df_to_names(df):\n",
    "    \n",
    "    name_dict = {}\n",
    "        \n",
    "    for i in range(1,len(df.columns)):\n",
    "        name = df.columns[i][:-2]\n",
    "        if name in name_dict:\n",
    "            name_dict[name].append(i)\n",
    "        else:\n",
    "            name_dict[name] = [i]\n",
    "            \n",
    "    return name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Create new temp dataframe with cols ['samp1a','samp1b','samp2a','samp2b','gene']\n",
    "### Add cols for logfc, pval\n",
    "def names_to_df(names):\n",
    "       \n",
    "    # For first name    \n",
    "    #print \"names to df\", names\n",
    "    indices = list(name_dict[names[0]])\n",
    "    indices.insert(0,0)\n",
    "    df_temp1 = df.ix[:,indices]\n",
    "    \n",
    "    # For second name\n",
    "    indices = list(name_dict[names[1]])\n",
    "    indices.insert(0,0)\n",
    "    df_temp2 = df.ix[:,indices]\n",
    "    \n",
    "    dft = pd.merge(df_temp1, df_temp2, how='outer', on='gene');\n",
    "    \n",
    "    #print \"check\"\n",
    "    dft = dft.ix[1:];\n",
    "    dft_float = dft.ix[:,1:].astype('float');\n",
    "    dft_float = dft_float[dft_float > 0];\n",
    "    #dft['pval'], dft['logfc'] = t_stat(dft_float);\n",
    "    dft['pval'] = t_stat(dft_float, names)[0]\n",
    "    dft['logfc'] = t_stat(dft_float, names)[1];\n",
    "    \n",
    "    #print dft_float.columns\n",
    "    return dft\n",
    "    #dft = merge(dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "p1 = names_to_df(pairs[0])['pval'][:10]\n",
    "p2 = names_to_df(pairs[3])['pval'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Needs dataframe with cols ('gene', 'logfc', 'pval')\n",
    "\n",
    "def filter_genes(df, pcut = 0.05, fcut = 1.4):\n",
    "    \n",
    "    df_pcut = df[df['pval'] < pcut]\n",
    "    \n",
    "    df_fc_up = df_pcut[df_pcut['logfc'] > fcut]\n",
    "    \n",
    "    df_fc_dn = df_pcut[df_pcut['logfc'] < -fcut]\n",
    "    \n",
    "    df_pv_up = df_pcut[df_pcut['logfc'] < fcut]\n",
    "    df_pv_up = df_pv_up[df_pv_up['logfc'] > 0]\n",
    "    \n",
    "    df_pv_dn = df_pcut[df_pcut['logfc'] < 0]\n",
    "    df_pv_dn = df_pv_dn[df_pv_dn['logfc'] > -fcut]\n",
    "\n",
    "    fc_up_genes = df_fc_up['gene']\n",
    "    fc_dn_genes = df_fc_dn['gene']\n",
    "    pv_up_genes = df_pv_up['gene']\n",
    "    pv_dn_genes = df_pv_dn['gene']\n",
    "    \n",
    "    #n_up_fc = sum(df_fc_up.ix[:,'up'])\n",
    "    #n_dn_fc = sum(df_fc_dn.ix[:,'dn'])\n",
    "    #n_up_pv = sum(df_pv_up.ix[:,'up'])\n",
    "    #n_dn_pv = sum(df_pv_dn.ix[:,'dn'])\n",
    "\n",
    "    return [fc_up_genes, fc_dn_genes, pv_up_genes, pv_dn_genes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#### [state1, state2, state3, ..., stateN]\n",
    "### [state1, state2, state3, ..., stateN]\n",
    "\n",
    "### N-1 combinations for each state\n",
    "### [state1-state2, state1-state3, state1-stateN ]\n",
    "\n",
    "### N/2 * N combinations, *2 for reverse\n",
    "\n",
    "### input dfs = [df1, df2]\n",
    "def compare_edges(dfs):\n",
    "    \n",
    "    df1_genes = filter_genes(dfs[0])\n",
    "    df2_genes = filter_genes(dfs[1])\n",
    "    \n",
    "    gene_totals = [[df1_genes[i], df2_genes[i]] for i in range(len(df1_genes))]\n",
    "    gene_intersect = [intersect(i,j) for i,j in gene_totals]\n",
    "    gene_percent = [float(len(gene_intersect[i]))/float(len(df1_genes[i])) for i in range(len(df1_genes))]\n",
    "    ### What do we want?\n",
    "    ### [[% up FC_1, % up FC_2],[% dn FC_1, %dn FC_1], [% up PV1, % up PV2], [% dn PV1, % dn PV2]]\n",
    "    \n",
    "    return gene_percent\n",
    "    \n",
    "    #n0 = len(dfres[k][0])\n",
    "    #n1 = len(dfres[k][1])\n",
    "    #ns = len(inter)\n",
    "    \n",
    "    #genes_shared_ct[k] = [n0, round(float(ns)/n0,3), n1, round(float(ns)/n1,3), ns]\n",
    "    #gene_totals[k] = [len(dfres[k][0]),len(dfres[k][1])] \n",
    "                      #genes_unique[k] = unique(dfres[k][0],dfres[k][1])\n",
    "    #gene_ratios[k] = len(genes_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_counts(names):\n",
    "    \n",
    "    dft = names_to_df(names)\n",
    "    dft_genes = filter_genes(dft)\n",
    "    dft_counts = [len(genes) for genes in dft_genes]\n",
    "    return dft_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_pair_counts(name_pairs):\n",
    "    \n",
    "    dft1 = names_to_df(name_pairs[0])\n",
    "    dft2 = names_to_df(name_pairs[1])\n",
    "    \n",
    "    dft1_genes = filter_genes(dft1)\n",
    "    dft2_genes = filter_genes(dft2)\n",
    "    \n",
    "    common_genes = [intersect(dft1_genes[i], dft2_genes[i]) for i in range(len(dft1_genes))]\n",
    "    common_counts = [len(genes) for genes in common_genes]\n",
    "    return common_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-317-25c5e9eb2a24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-201-a33f32b03b80>\u001b[0m in \u001b[0;36mall_counts\u001b[0;34m(pairs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#pair in pairs:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mpairs2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-faea7dca1206>\u001b[0m in \u001b[0;36mget_counts\u001b[0;34m(names)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdft_genes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_genes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdft_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgenes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdft_genes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-288-c1701392008f>\u001b[0m in \u001b[0;36mnames_to_df\u001b[0;34m(names)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# For first name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print \"names to df\", names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf_temp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "all_counts(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_counts(pairs):\n",
    "    \n",
    "    pairs = reset_pairs(df)\n",
    "    pairs2 = list(pairs)\n",
    "    \n",
    "    for p in range(len(pairs)):\n",
    "        #pair in pairs:\n",
    "        counts = get_counts(pairs2[p])\n",
    "        pairs2[p].append(counts)\n",
    "        \n",
    "    return pairs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def abb_pairs(pairs):\n",
    "    #print pairs\n",
    "    abb_pairs = [[abb_pair_dict[i], abb_pair_dict[j]] for i, j in pairs]\n",
    "    return abb_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def common_counts(pairs):\n",
    "    \n",
    "    pairs = reset_pairs(df)\n",
    "    pairs_temp = list(pairs)\n",
    "    data = []\n",
    "    \n",
    "    for p in range(len(pairs)):\n",
    "        pair1 = pairs[p]\n",
    "        \n",
    "        for p2 in range(p+1,len(pairs)): \n",
    "            pair2 = pairs[p2]\n",
    "            #if pair1 != pair2:\n",
    "            counts = pair_pair_counts([pair1, pair2])\n",
    "            data12 = [[pair1, pair2],[counts]]\n",
    "            data.append(data12)\n",
    "            \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def common_ratio(pairs):\n",
    "    \n",
    "    pairs = reset_pairs(df)\n",
    "    pairs_temp = list(pairs)\n",
    "    data = []\n",
    "    \n",
    "    for p in range(len(pairs)):\n",
    "        pair1 = pairs[p]\n",
    "        \n",
    "        for p2 in range(p+1,len(pairs)): \n",
    "            pair2 = pairs[p2]\n",
    "            #if pair1 != pair2:\n",
    "            counts = pair_pair_counts([pair1, pair2])\n",
    "            data12 = [[pair1, pair2],float(counts[0])/float(counts[1])]\n",
    "            data.append(data12)\n",
    "            \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def uncommon_counts(pairs):\n",
    "    \n",
    "    pairs = reset_pairs(df)\n",
    "    pairs_temp = list(pairs)\n",
    "    data = []\n",
    "    \n",
    "    for p in range(len(pairs)):\n",
    "        pair1 = pairs[p]\n",
    "        counts1 = get_counts(pair1)\n",
    "        for p2 in range(p+1,len(pairs)): \n",
    "            pair2 = pairs[p2]\n",
    "            #if pair1 != pair2:\n",
    "            counts2 = get_counts(pair2)\n",
    "            counts_pair = pair_pair_counts([pair1, pair2])\n",
    "            data12 = [[pair1, counts1, pair2, counts2],[counts_pair]]\n",
    "            data.append(data12)\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_data = common_ratio(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_data.sort(key=itemgetter(1), reverse=True) #, keyfor pairs in count_data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['YN', 'YF'], ['YN', 'OF']], 8.666666666666666]\n",
      "[[['ON', 'YF'], ['ON', 'OF']], 5.65625]\n",
      "[[['YN', 'ON'], ['YN', 'YF']], 2.272727272727273]\n",
      "[[['OF', 'YN'], ['OF', 'YF']], 1.3225806451612903]\n",
      "[[['YN', 'ON'], ['YN', 'OF']], 1.3055555555555556]\n",
      "[[['ON', 'YN'], ['ON', 'YF']], 1.05]\n",
      "[[['ON', 'YN'], ['ON', 'OF']], 0.7692307692307693]\n",
      "[[['YF', 'ON'], ['YF', 'OF']], 0.75]\n",
      "[[['OF', 'ON'], ['OF', 'YF']], 0.75]\n",
      "[[['YF', 'YN'], ['YF', 'OF']], 0.7272727272727273]\n",
      "[[['YF', 'ON'], ['YF', 'YN']], 0.12716763005780346]\n",
      "[[['OF', 'ON'], ['OF', 'YN']], 0.08376963350785341]\n"
     ]
    }
   ],
   "source": [
    "for data in count_data:\n",
    "    if data[0][0][0] == data[0][1][0]:\n",
    "        print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[['ON', 'YF'], ['YN', 'OF']], 16.4],\n",
       " [[['YN', 'YF'], ['ON', 'OF']], 14.75],\n",
       " [[['ON', 'OF'], ['YN', 'OF']], 11.9375],\n",
       " [[['YN', 'YF'], ['YN', 'OF']], 8.666666666666666],\n",
       " [[['ON', 'YF'], ['YN', 'YF']], 7.863636363636363],\n",
       " [[['ON', 'YF'], ['ON', 'OF']], 5.65625],\n",
       " [[['YN', 'ON'], ['YN', 'YF']], 2.272727272727273],\n",
       " [[['YN', 'ON'], ['ON', 'OF']], 2.25],\n",
       " [[['YN', 'ON'], ['ON', 'YF']], 1.7142857142857142],\n",
       " [[['YF', 'ON'], ['ON', 'OF']], 1.5],\n",
       " [[['YN', 'YF'], ['OF', 'YF']], 1.375],\n",
       " [[['ON', 'YF'], ['OF', 'YF']], 1.3333333333333333],\n",
       " [[['YN', 'YF'], ['YF', 'OF']], 1.3333333333333333],\n",
       " [[['ON', 'OF'], ['YF', 'OF']], 1.3333333333333333],\n",
       " [[['OF', 'YN'], ['OF', 'YF']], 1.3225806451612903],\n",
       " [[['YN', 'ON'], ['YN', 'OF']], 1.3055555555555556],\n",
       " [[['YN', 'ON'], ['OF', 'ON']], 1.3],\n",
       " [[['ON', 'YN'], ['OF', 'YF']], 1.2222222222222223],\n",
       " [[['YF', 'ON'], ['YN', 'YF']], 1.1666666666666667],\n",
       " [[['OF', 'ON'], ['YF', 'OF']], 1.1666666666666667],\n",
       " [[['ON', 'YN'], ['YF', 'OF']], 1.1666666666666667],\n",
       " [[['YF', 'YN'], ['ON', 'OF']], 1.1666666666666667],\n",
       " [[['YF', 'YN'], ['YN', 'OF']], 1.1666666666666667],\n",
       " [[['OF', 'YN'], ['YF', 'OF']], 1.1666666666666667],\n",
       " [[['ON', 'YN'], ['YN', 'OF']], 1.125],\n",
       " [[['ON', 'YN'], ['ON', 'YF']], 1.05],\n",
       " [[['YF', 'ON'], ['YN', 'OF']], 1.0476190476190477],\n",
       " [[['YN', 'ON'], ['ON', 'YN']], 1.0],\n",
       " [[['YN', 'ON'], ['YF', 'YN']], 1.0],\n",
       " [[['YF', 'ON'], ['ON', 'YF']], 1.0],\n",
       " [[['YF', 'ON'], ['OF', 'YF']], 1.0],\n",
       " [[['OF', 'ON'], ['ON', 'OF']], 1.0],\n",
       " [[['OF', 'ON'], ['YN', 'OF']], 1.0],\n",
       " [[['ON', 'YN'], ['YN', 'YF']], 1.0],\n",
       " [[['YF', 'YN'], ['YN', 'YF']], 1.0],\n",
       " [[['OF', 'YN'], ['ON', 'OF']], 1.0],\n",
       " [[['OF', 'YN'], ['YN', 'OF']], 1.0],\n",
       " [[['ON', 'YF'], ['YF', 'OF']], 1.0],\n",
       " [[['OF', 'YF'], ['YF', 'OF']], 1.0],\n",
       " [[['OF', 'YN'], ['ON', 'YF']], 0.9545454545454546],\n",
       " [[['YN', 'ON'], ['YF', 'ON']], 0.9523809523809523],\n",
       " [[['YN', 'ON'], ['OF', 'YN']], 0.8888888888888888],\n",
       " [[['YN', 'ON'], ['OF', 'YF']], 0.8571428571428571],\n",
       " [[['OF', 'ON'], ['YN', 'YF']], 0.8571428571428571],\n",
       " [[['YF', 'YN'], ['ON', 'YF']], 0.8571428571428571],\n",
       " [[['OF', 'YN'], ['YN', 'YF']], 0.8571428571428571],\n",
       " [[['OF', 'YF'], ['ON', 'OF']], 0.8571428571428571],\n",
       " [[['OF', 'YF'], ['YN', 'OF']], 0.8571428571428571],\n",
       " [[['YN', 'ON'], ['YF', 'OF']], 0.8181818181818182],\n",
       " [[['ON', 'YN'], ['ON', 'OF']], 0.7692307692307693],\n",
       " [[['ON', 'YN'], ['OF', 'YN']], 0.7659574468085106],\n",
       " [[['YN', 'OF'], ['YF', 'OF']], 0.7560975609756098],\n",
       " [[['YF', 'ON'], ['YF', 'OF']], 0.75],\n",
       " [[['OF', 'ON'], ['OF', 'YF']], 0.75],\n",
       " [[['YF', 'YN'], ['OF', 'YF']], 0.75],\n",
       " [[['YF', 'YN'], ['YF', 'OF']], 0.7272727272727273],\n",
       " [[['OF', 'ON'], ['ON', 'YF']], 0.6666666666666666],\n",
       " [[['YF', 'ON'], ['ON', 'YN']], 0.5833333333333334],\n",
       " [[['OF', 'ON'], ['ON', 'YN']], 0.4444444444444444],\n",
       " [[['ON', 'YN'], ['YF', 'YN']], 0.44],\n",
       " [[['YF', 'ON'], ['OF', 'ON']], 0.17679558011049723],\n",
       " [[['YF', 'ON'], ['YF', 'YN']], 0.12716763005780346],\n",
       " [[['YF', 'YN'], ['OF', 'YN']], 0.11538461538461539],\n",
       " [[['OF', 'ON'], ['OF', 'YN']], 0.08376963350785341],\n",
       " [[['OF', 'ON'], ['YF', 'YN']], 0.06779661016949153],\n",
       " [[['YF', 'ON'], ['OF', 'YN']], 0.06097560975609756]]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-353-0f4d51df608a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#count_data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mc2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcount_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mcount_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "c2 = count_data\n",
    "for c in range(len(count_data)): #count_data:\n",
    "    c2[c][1][0] = count_data[c][1][0][0]/count_data[c][1][0][0]\n",
    "    \n",
    "print count_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['ON', 'YN'], ['ON', 'YF']], [[42, 40, 157, 177]]]\n",
      "[[['ON', 'YN'], ['OF', 'YN']], [[36, 47, 278, 132]]]\n",
      "[[['ON', 'YN'], ['OF', 'YF']], [[33, 27, 94, 81]]]\n",
      "[[['ON', 'YN'], ['YF', 'YN']], [[11, 25, 155, 70]]]\n",
      "[[['ON', 'YN'], ['ON', 'OF']], [[10, 13, 88, 135]]]\n",
      "[[['ON', 'YN'], ['YN', 'OF']], [[9, 8, 10, 11]]]\n",
      "[[['ON', 'YN'], ['YN', 'YF']], [[7, 7, 38, 30]]]\n",
      "[[['ON', 'YN'], ['YF', 'OF']], [[7, 6, 1, 2]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for data in count_data:\n",
    "    if data[0][0][0] == 'ON' and 'YN' in data[0][0]:\n",
    "        print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['AT2.young.flu.20150416', 'AT2.old.naive.20150416', [707, 776, 1524, 1337]],\n",
       " ['AT2.old.flu.20150416', 'AT2.old.naive.20150416', [624, 728, 1453, 1050]],\n",
       " ['AT2.young.naive.20150416', 'AT2.old.naive.20150416', [653, 566, 701, 588]],\n",
       " ['AT2.old.naive.20150416', 'AT2.young.flu.20150416', [776, 707, 1337, 1524]],\n",
       " ['AT2.old.flu.20150416', 'AT2.young.flu.20150416', [578, 495, 503, 436]],\n",
       " ['AT2.young.naive.20150416',\n",
       "  'AT2.young.flu.20150416',\n",
       "  [740, 486, 1041, 1077]],\n",
       " ['AT2.old.naive.20150416', 'AT2.old.flu.20150416', [728, 624, 1050, 1453]],\n",
       " ['AT2.young.flu.20150416', 'AT2.old.flu.20150416', [495, 578, 436, 503]],\n",
       " ['AT2.young.naive.20150416', 'AT2.old.flu.20150416', [806, 652, 997, 1361]],\n",
       " ['AT2.old.naive.20150416', 'AT2.young.naive.20150416', [566, 653, 588, 701]],\n",
       " ['AT2.young.flu.20150416',\n",
       "  'AT2.young.naive.20150416',\n",
       "  [486, 740, 1077, 1041]],\n",
       " ['AT2.old.flu.20150416', 'AT2.young.naive.20150416', [652, 806, 1361, 997]]]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%capture\n",
    "al_counts(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = [\"FC up\", \"FC down\", \"PV up\", \"PV down\"]\n",
    "for i in range(4):\n",
    "    print names[i]\n",
    "    print x[i]\n",
    "    #print genes_shared_ct[i] #\".2f\"% genes_shared_ct[i][1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot([0.6, 0.2, 0.6, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dft = dft[pd.notnull(dft).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ncols = len(dft.columns)\n",
    "gene_names = dft.ix[:,0]\n",
    "for i in range(1, ncols, 4):   #ncols):\n",
    "    sample1_name = dft.columns[i]\n",
    "    sample_list = []\n",
    "    sample1 = dft.ix[:,i]\n",
    "    for j in range(1, ncols):\n",
    "        \n",
    "        sample2_name = dft.columns[j]\n",
    "        \n",
    "        sample2 = dft.ix[:,j]\n",
    "        #print sample1[0], sample2[0]\n",
    "        logfc = np.log(sample2/sample1)\n",
    "        logfc = logfc[logfc < 100]\n",
    "        upreg = len(logfc[logfc > 1.4])\n",
    "        downreg = len(logfc[logfc < -1.4])\n",
    "        #print sample1_name, sample2_name, upreg, downreg\n",
    "        dist = upreg + downreg\n",
    "        regratio = upreg - downreg\n",
    "        sample_list.append([sample2_name, dist, upreg, downreg])\n",
    "        \n",
    "    print sample1_name\n",
    "    for n in sample_list:\n",
    "        print n\n",
    "    #print sample_list\n",
    "#        print sample1/sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_tree(dfs):\n",
    "    ndf = len(dfs)\n",
    "    mat\n",
    "    for df1_ind in range(ndf):\n",
    "        for df2_ind in range(df1_ind+1,ndf):\n",
    "            merged_df = pd.merge(dfs[df1_ind], dfs[df2_ind], how = 'outer', on='gene')\n",
    "            \n",
    "            #merged_df['ratio'] = float(merged_df[[1]]) #sum(float(merged_df[[1,2,3,4]]))\n",
    "            #for gene_ind in range(len(merged_df)):\n",
    "        ### GET ratios\n",
    "                \n",
    "        ### GET SIMILARITY\n",
    "        ### [ YN [1, 0.4, 0.8. 0.7],\n",
    "        ###   ON [0.6, 1, 0.9, 0.2],\n",
    "        ###   YF [0.4, 0.3, 1, 0.6],\n",
    "        ###   OF [0.3, 0.9, 0.1, 1]]\n",
    "        \n",
    "        ### TREE FIGURE\n",
    "        ###      YF (2)\n",
    "        ###     /\n",
    "        ###  YN(1)- ON(3)- OF(4)\n",
    "        \n",
    "        ###  [[1,2],[1,3],[3,4]]\n",
    "        \n",
    "        ### START WITH\n",
    "        ### [[1,2],[1,3],[1,4]]\n",
    "        ### [1-2] 0.3\n",
    "        ### [1-3] 0.8\n",
    "        ### [1-4] 0.5\n",
    "        ### Then go to 2\n",
    "        ### [2-1] 0.3 (ok)\n",
    "        ### [2-3] 0.9 (>[1-3], change)\n",
    "                    ### [[1,2],[2,3],[1,4]]\n",
    "        ### [2-4] 0.2 (<[1-4], no change)\n",
    "        ### On to 3...\n",
    "        ### [3-1] 0.3 (ok)\n",
    "        ### [3-2] 0.1 (<[1-3], no change)\n",
    "        ### [3-4] 0.9 (>[1-4], change\n",
    "                    ### [[1,2],[1,3],[3,4]])\n",
    "        \n",
    "        ### [1-3] ok\n",
    "        sim = [[random.random() for i in range(ndf)] for j in range(ndf)]\n",
    "        for i in range(ndf):\n",
    "            ## Initialize tree starting with i\n",
    "            tree = []\n",
    "            for j in range(ndf):\n",
    "                tree[j] = [i,j]\n",
    "                #similarity_matrix sim\n",
    "                \n",
    "                \n",
    "            for j in range(ndf):\n",
    "                sim_ij = sim[i,j]\n",
    "                for k in range(ndf):\n",
    "                    sim_ik = sim[i,k]\n",
    "                    if sim_ik > sim_ij:\n",
    "                        tree[j] = [i,k]\n",
    "                    \n",
    "                \n",
    "                \n",
    "    \n",
    "    #return merged_df\n",
    "        \n",
    "            \n",
    "make_tree(dfs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "ndf = 4\n",
    "sim = [[random.random() for i in range(ndf)] for j in range(ndf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim[2][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_tree2():\n",
    "    ndf = 10\n",
    "    sim = [[random.random() for i in range(ndf)] for j in range(ndf)]\n",
    "    nodes = [i for i in range(ndf)]\n",
    "    for i in range(ndf):\n",
    "        #print \"begin\", i\n",
    "            ## Initialize tree starting with i\n",
    "        tree = []# [0 for x in range(ndf-1)]\n",
    "        \n",
    "        j_nodes = [z for z in range(ndf)]\n",
    "        j_nodes.remove(i)\n",
    "        for j in j_nodes: \n",
    "            tree.append([i,j])\n",
    "                #similarity_matrix sim\n",
    "                \n",
    "        n_iters = 1\n",
    "        for iteration in range(n_iters):\n",
    "            \n",
    "            #print tree\n",
    "        #print \"j_nodes\",j_nodes\n",
    "            for j in j_nodes:\n",
    "            #print tree\n",
    "                sim_ij = sim[i][j]\n",
    "            \n",
    "                k_nodes = [z for z in range(ndf)]\n",
    "                k_nodes.remove(j)\n",
    "                k_nodes.remove(i)\n",
    "                #print \"k_nodes\", k_nodes\n",
    "                for k in k_nodes:\n",
    "                #print \"j = \", j, \"k=\", k\n",
    "                    sim_ik = sim[i][k]\n",
    "                    sim_jk = sim[j][k]\n",
    "                    if sim_ik > sim_jk:\n",
    "                        #print j,k, \"> \", i, k\n",
    "                        tree[k-1] = [j,k]\n",
    "                        #print tree\n",
    "            #print \"end iteration\", iteration, tree\n",
    "            #for i in range(len(tree)):\n",
    "            print sum([sim[ii][jj] for ii,jj in tree])\n",
    "        printsorted(tree)\n",
    "make_tree2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_tree_rand():\n",
    "    ndf = 10\n",
    "    sim = [[random.random() for i in range(ndf)] for j in range(ndf)]\n",
    "    seq = [i for i in range(ndf)]\n",
    "\n",
    "    nodes = [random.choice() for i in range(ndf)]\n",
    "    n_iter = 10\n",
    "    \n",
    "    ### Initialize tree\n",
    "    tree = []# [0 for x in range(ndf-1)]\n",
    "    \n",
    "    j_nodes = [z for z in range(ndf)]\n",
    "    j_nodes.remove(i)\n",
    "    for j in j_nodes: \n",
    "        tree.append([i,j])\n",
    "                #similarity_matrix sim\n",
    "    for i in range(n_iter):\n",
    "        #print \"begin\", i\n",
    "            ## Initialize tree starting with i\n",
    "\n",
    "                \n",
    "        n_iters = 1\n",
    "        for iteration in range(n_iters):\n",
    "            \n",
    "            #print tree\n",
    "        #print \"j_nodes\",j_nodes\n",
    "            for j in j_nodes:\n",
    "            #print tree\n",
    "                sim_ij = sim[i][j]\n",
    "            \n",
    "                k_nodes = [z for z in range(ndf)]\n",
    "                k_nodes.remove(j)\n",
    "                k_nodes.remove(i)\n",
    "                #print \"k_nodes\", k_nodes\n",
    "                for k in k_nodes:\n",
    "                #print \"j = \", j, \"k=\", k\n",
    "                    sim_ik = sim[i][k]\n",
    "                    sim_jk = sim[j][k]\n",
    "                    if sim_ik > sim_jk:\n",
    "                        #print j,k, \"> \", i, k\n",
    "                        tree[k-1] = [j,k]\n",
    "                        #print tree\n",
    "            #print \"end iteration\", iteration, tree\n",
    "            #for i in range(len(tree)):\n",
    "            error = sum([sim[ii][jj] for ii,jj in tree])\n",
    "        printsorted(tree)\n",
    "make_tree_rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_tree_easy():\n",
    "    ndf = 10\n",
    "    sim = [[random.random() for i in range(ndf)] for j in range(ndf)]\n",
    "    seq = [i for i in range(ndf)]\n",
    "\n",
    "    nodes = [random.choice() for i in range(ndf)]\n",
    "    n_iter = 10\n",
    "    \n",
    "    ### Initialize tree\n",
    "    tree = []# [0 for x in range(ndf-1)]\n",
    "    \n",
    "    j_nodes = [z for z in range(ndf)]\n",
    "    j_nodes.remove(i)\n",
    "    for j in j_nodes: \n",
    "        tree.append([i,j])\n",
    "                #similarity_matrix sim\n",
    "    for i in range(n_iter):\n",
    "        #print \"begin\", i\n",
    "            ## Initialize tree starting with i\n",
    "\n",
    "                \n",
    "        n_iters = 1\n",
    "        for iteration in range(n_iters):\n",
    "            \n",
    "            #print tree\n",
    "        #print \"j_nodes\",j_nodes\n",
    "            for j in j_nodes:\n",
    "            #print tree\n",
    "                sim_ij = sim[i][j]\n",
    "            \n",
    "                k_nodes = [z for z in range(ndf)]\n",
    "                k_nodes.remove(j)\n",
    "                k_nodes.remove(i)\n",
    "                #print \"k_nodes\", k_nodes\n",
    "                for k in k_nodes:\n",
    "                #print \"j = \", j, \"k=\", k\n",
    "                    sim_ik = sim[i][k]\n",
    "                    sim_jk = sim[j][k]\n",
    "                    if sim_ik > sim_jk:\n",
    "                        #print j,k, \"> \", i, k\n",
    "                        tree[k-1] = [j,k]\n",
    "                        #print tree\n",
    "            #print \"end iteration\", iteration, tree\n",
    "            #for i in range(len(tree)):\n",
    "            error = sum([sim[ii][jj] for ii,jj in tree])\n",
    "        printsorted(tree)\n",
    "make_tree_easy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printsorted(tree):\n",
    "    tree.sort()\n",
    "    tree_dict = {}\n",
    "    for i in range(len(tree)):\n",
    "        if tree[i][0] not in tree_dict:\n",
    "            tree_dict[tree[i][0]] = [tree[i][1]]\n",
    "        else:\n",
    "            tree_dict[tree[i][0]].append(tree[i][1])\n",
    "        \n",
    "    print tree_dict\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
